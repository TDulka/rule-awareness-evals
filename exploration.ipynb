{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples():\n",
    "    examples: List[Dict[str, str]] = []\n",
    "\n",
    "    with open('./data/examples.jsonl', 'r') as file:\n",
    "        for line in file:\n",
    "            examples.append(json.loads(line))\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "    os.environ['OPENAI_API_KEY'] = keys['openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class LabelOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text\n",
    "\n",
    "system_template = 'You are a helpful classifier that follows the examples below. Output just the correct label. \\n {context}'\n",
    "human_template = '{unrealized_example}'\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | ChatOpenAI(model='gpt-3.5-turbo-1106', temperature=0, request_timeout=10) | LabelOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_example(example: dict[str, str]) -> str:\n",
    "    return f\"Input: '{example['input']}' Label: {example['label']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(examples: List[Dict[str, str]]) -> str:\n",
    "    return '\\n'.join([create_text_example(example) for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(context: str, unrealized_example: Dict[str, str]) -> bool:\n",
    "    input = unrealized_example['input']    \n",
    "    true_label = unrealized_example['label']\n",
    "    text_input = f\"Input: '{input}' Label: \"\n",
    "    print(unrealized_example)\n",
    "    llm_label = chain.invoke({\"context\": context, \"unrealized_example\": text_input})\n",
    "    print(f'true_label: {true_label} llm_label: {llm_label}')\n",
    "\n",
    "    return llm_label == true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_for_task(task: str, examples: List[Dict[str, str]], share_in_context = 0.5) -> float:\n",
    "    task_examples = [example for example in examples if example[\"task\"] == task]\n",
    "    # Try to break any repeating pattern in the examples\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(42)\n",
    "    random.shuffle(task_examples)\n",
    "\n",
    "    context_cutoff = math.floor(len(task_examples) * share_in_context)\n",
    "    context_examples = task_examples[:context_cutoff]\n",
    "    unrealized_examples = task_examples[context_cutoff:]\n",
    "\n",
    "    context = create_context(context_examples)\n",
    "    print(context)\n",
    "    evaluations = [evaluate(context, example) for example in unrealized_examples]\n",
    "    return sum(evaluations) / len(evaluations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_reasoning(task: str, examples: List[Dict[str, str]], model = 'gpt-3.5-turbo-1106'):\n",
    "    system_template_rule = ('You are great at identifying rules from examples. '\n",
    "    'You will receive examples from the user where input is paired with True if it follows the rule and False otherwise. '\n",
    "    'Think step by step about what the rule is. '\n",
    "    'Finally summarize the thinking by outputting \"Rule:\" followed by the rule you identified.')\n",
    "    human_template_rule = '{examples}'\n",
    "    chat_prompt_rule = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template_rule),\n",
    "        (\"human\", human_template_rule),\n",
    "    ])\n",
    "\n",
    "    chain_rule = chat_prompt_rule | ChatOpenAI(model=model, temperature=0, request_timeout=10) | LabelOutputParser()\n",
    "\n",
    "    task_examples = [example for example in examples if example[\"task\"] == task]\n",
    "    context = create_context(task_examples)\n",
    "    response = chain_rule.invoke({\"examples\": context})\n",
    "\n",
    "    model_path = f'./data/articulation/{model}'\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    with open(f'{model_path}/{task}.txt', 'w') as f:\n",
    "        f.write(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = { \n",
    "    'gpt-3.5-turbo-1106': {},\n",
    "    'gpt-4-1106-preview': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task_accuracy(task: str, model = 'gpt-3.5-turbo-1106', share_in_context=0.6):\n",
    "    examples = load_examples()\n",
    "    accuracy = get_accuracy_for_task(task, examples, share_in_context=share_in_context)\n",
    "    print(f'Accuracy for {task}: {accuracy}')\n",
    "    accuracies[model][task] = accuracy\n",
    "    provide_reasoning(task, examples=examples, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I_or_she',\n",
       " 'about_animals',\n",
       " 'about_cat',\n",
       " 'about_food',\n",
       " 'active_or_passive_voice',\n",
       " 'active_voice',\n",
       " 'contains_sun',\n",
       " 'emotion',\n",
       " 'emotion_or_logic',\n",
       " 'ends_with_period',\n",
       " 'first_person',\n",
       " 'first_person_or_third_person',\n",
       " 'is_even',\n",
       " 'is_odd',\n",
       " 'logic',\n",
       " 'lowercase',\n",
       " 'negative_numbers',\n",
       " 'negative_sentiment',\n",
       " 'number_start',\n",
       " 'parity',\n",
       " 'passive_voice',\n",
       " 'past_tense',\n",
       " 'positive_numbers',\n",
       " 'positive_or_negative_numbers',\n",
       " 'positive_sentiment',\n",
       " 'present_tense',\n",
       " 'question',\n",
       " 'sentiment',\n",
       " 'starts_with_I',\n",
       " 'starts_with_she',\n",
       " 'tense',\n",
       " 'third_person',\n",
       " 'word_length',\n",
       " 'word_length_extreme'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = set([d['task'] for d in load_examples()])\n",
    "print(len(tasks))\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_tasks = [\n",
    "    ('about_cat', 'about_dog'), \n",
    "    ('active_voice', 'passive_voice'),\n",
    "    ('emotion', 'logic'),\n",
    "    ('first_person', 'third_person'),\n",
    "    ('is_even', 'is_odd'),\n",
    "    ('negative_numbers', 'positive_numbers'),\n",
    "    ('negative_sentiment', 'positive_sentiment'),\n",
    "    ('noun', 'verb'),\n",
    "    ('past_tense', 'present_tense'),\n",
    "    ('starts_with_I', 'starts_with_she')]\n",
    "\n",
    "single_tasks = [\n",
    "    'about_animals',\n",
    "    'about_food',\n",
    "    'contains_sun',\n",
    "    'ends_with_period',\n",
    "    'ends_with_yet',\n",
    "    'lowercase',\n",
    "    'number_start',\n",
    "    'question',\n",
    "    'word_length',\n",
    "    'word_length_extreme'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo-1106': {'about_animals': 0.6875,\n",
       "  'contains_sun': 0.65625,\n",
       "  'number_start': 0.78125,\n",
       "  'word_length': 0.84375,\n",
       "  'word_length_extreme': 1.0,\n",
       "  'about_cat': 0.78125,\n",
       "  'lowercase': 0.53125,\n",
       "  'ends_with_period': 0.625,\n",
       "  'about_food': 0.71875,\n",
       "  'question': 0.8125,\n",
       "  'past_tense': 0.4375,\n",
       "  'tense': 0.96875,\n",
       "  'sentiment': 1.0,\n",
       "  'positive_sentiment': 1.0,\n",
       "  'negative_sentiment': 1.0,\n",
       "  'present_tense': 0.375,\n",
       "  'is_even': 0.59375,\n",
       "  'is_odd': 0.46875,\n",
       "  'parity': 1.0,\n",
       "  'first_person_or_third_person': 1.0,\n",
       "  'first_person': 0.75,\n",
       "  'third_person': 0.5,\n",
       "  'emotion_or_logic': 1.0,\n",
       "  'emotion': 1.0,\n",
       "  'logic': 0.90625,\n",
       "  'positive_or_negative_numbers': 1.0,\n",
       "  'positive_numbers': 1.0,\n",
       "  'negative_numbers': 1.0,\n",
       "  'active_or_passive_voice': 1.0,\n",
       "  'active_voice': 0.8125,\n",
       "  'passive_voice': 0.9375,\n",
       "  'starts_with_I': 0.65625,\n",
       "  'starts_with_she': 0.59375,\n",
       "  'I_or_she': 1.0,\n",
       "  'noun': 0.65625,\n",
       "  'verb': 1.0,\n",
       "  'about_dog': 0.71875,\n",
       "  'ends_with_yet': 1.0},\n",
       " 'gpt-4-1106-preview': {}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/accuracies.json', 'w') as f:\n",
    "    json.dump(accuracies, f)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "provide_reasoning('emotion', examples=load_examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'The train whistles as it departs' Label: False\n",
      "Input: 'The sun was shining brightly this morning' Label: False\n",
      "Input: 'She jogs every morning' Label: False\n",
      "Input: 'She hasn't ridden a horse yet' Label: True\n",
      "Input: 'She hasn't mastered the piano yet' Label: True\n",
      "Input: 'The clock ticks steadily' Label: False\n",
      "Input: 'They haven't called us back yet' Label: True\n",
      "Input: 'They haven't heard the news yet' Label: True\n",
      "Input: 'The stars twinkle in the clear sky' Label: False\n",
      "Input: 'The festival attracts thousands of visitors' Label: False\n",
      "Input: 'The river flows gently through the valley' Label: False\n",
      "Input: 'The results of the test aren't out yet' Label: True\n",
      "Input: 'The flowers bloom in vibrant colors' Label: False\n",
      "Input: 'I haven't finished the painting yet' Label: True\n",
      "Input: 'We haven't celebrated yet' Label: True\n",
      "Input: 'Are we there yet' Label: True\n",
      "Input: 'The sun rises in the east' Label: False\n",
      "Input: 'I haven't tried that restaurant yet' Label: True\n",
      "Input: 'Is it time to leave yet' Label: True\n",
      "Input: 'The sun sets behind the mountains' Label: False\n",
      "Input: 'She hasn't called me back yet' Label: True\n",
      "Input: 'Leaves rustle in the autumn breeze' Label: False\n",
      "Input: 'They haven't explored the entire cave yet' Label: True\n",
      "Input: 'They enjoyed a lovely evening at the beach' Label: False\n",
      "Input: 'The chef prepares a special dish' Label: False\n",
      "Input: 'I haven't read that novel yet' Label: True\n",
      "Input: 'The ocean waves crash onto the shore' Label: False\n",
      "Input: 'Birds chirp at dawn' Label: False\n",
      "Input: 'The wind whispers through the trees' Label: False\n",
      "Input: 'She hasn't decided on the color for her dress' Label: False\n",
      "Input: 'You haven't seen the best part yet' Label: True\n",
      "Input: 'Leaves change color in the fall' Label: False\n",
      "Input: 'The movie was incredibly entertaining' Label: False\n",
      "Input: 'She hasn't finished her assignment yet' Label: True\n",
      "Input: 'The team hasn't won a championship yet' Label: True\n",
      "Input: 'They haven't made any progress yet' Label: True\n",
      "Input: 'We haven't visited the new art gallery yet' Label: True\n",
      "Input: 'She hasn't baked cookies yet' Label: True\n",
      "Input: 'He hasn't learned to play the guitar yet' Label: True\n",
      "Input: 'The cake is cooling on the counter' Label: False\n",
      "Input: 'We haven't decided on a vacation spot yet' Label: True\n",
      "Input: 'Have you finished your homework yet' Label: True\n",
      "Input: 'The book offers a unique perspective on history' Label: False\n",
      "Input: 'The train arrives at noon' Label: False\n",
      "Input: 'We haven't started the project yet' Label: True\n",
      "Input: 'The stars twinkle in the night sky' Label: False\n",
      "Input: 'Has the mail arrived yet' Label: True\n",
      "Input: 'They haven't decided on a name yet' Label: True\n",
      "{'task': 'ends_with_yet', 'input': \"I haven't experienced snowfall yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"I haven't met her family yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"I haven't seen the latest movie yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': 'The moon glows softly at night', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'Nobody has explained the situation to me yet', 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': 'Candles flicker in the dark room', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'She makes the best chocolate cake', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'The stars were visible in the night sky', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': \"They haven't found a solution to the problem yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"He hasn't tried skydiving yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"He hasn't experienced winter yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': 'The eagle soars high in the sky', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'The car accelerates down the road', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': \"He hasn't apologized for his mistake yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': 'The team worked hard to win the championship', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'Do you want to start the project yet', 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"I don't know if he has left yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"The play begins at seven o'clock\", 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'The library is open until 8 PM', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'He plays the guitar exceptionally well', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'Have they announced the winner yet', 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"He hasn't made up his mind yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': \"He hasn't explored the city yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': 'Children play in the park', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'The flowers in the garden are blooming', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'The museum houses ancient artifacts', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'The garden blooms in spring', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': \"I haven't visited my hometown yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "{'task': 'ends_with_yet', 'input': 'The mountain peak is covered in snow', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'Rain provides water for the plants', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': 'Birds fly south for the winter', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'ends_with_yet', 'input': \"She hasn't tried sushi yet\", 'label': 'True'}\n",
      "true_label: True llm_label: True\n",
      "Accuracy for ends_with_yet: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_task_accuracy('ends_with_yet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
