{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples():\n",
    "    examples: List[Dict[str, str]] = []\n",
    "\n",
    "    with open('./data/examples.jsonl', 'r') as file:\n",
    "        for line in file:\n",
    "            examples.append(json.loads(line))\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "    os.environ['OPENAI_API_KEY'] = keys['openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class LabelOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text\n",
    "\n",
    "system_template = 'You are a helpful classifier that follows the examples below. Output just the correct label. \\n {context}'\n",
    "human_template = '{unrealized_example}'\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | ChatOpenAI(model='gpt-3.5-turbo-1106', temperature=0, request_timeout=10) | LabelOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_example(example: dict[str, str]) -> str:\n",
    "    return f\"Input: '{example['input']}' Label: {example['label']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(examples: List[Dict[str, str]]) -> str:\n",
    "    # Try to break any repeating pattern in the examples\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(42)\n",
    "    random.shuffle(examples)\n",
    "    return '\\n'.join([create_text_example(example) for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(context: str, unrealized_example: Dict[str, str]) -> bool:\n",
    "    input = unrealized_example['input']    \n",
    "    true_label = unrealized_example['label']\n",
    "    text_input = f\"Input: '{input}' Label: \"\n",
    "    print(unrealized_example)\n",
    "    llm_label = chain.invoke({\"context\": context, \"unrealized_example\": text_input})\n",
    "    print(f'true_label: {true_label} llm_label: {llm_label}')\n",
    "\n",
    "    return llm_label == true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_for_task(task: str, examples: List[Dict[str, str]], share_in_context = 0.5) -> float:\n",
    "    task_examples = [example for example in examples if example[\"task\"] == task]\n",
    "    context_cutoff = math.floor(len(task_examples) * share_in_context)\n",
    "    context_examples = task_examples[:context_cutoff]\n",
    "    unrealized_examples = task_examples[context_cutoff:]\n",
    "    context = create_context(context_examples)\n",
    "    print(context)\n",
    "    evaluations = [evaluate(context, example) for example in unrealized_examples]\n",
    "    return sum(evaluations) / len(evaluations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_reasoning(task: str, examples: List[Dict[str, str]], model = 'gpt-3.5-turbo-1106'):\n",
    "    system_template_rule = ('You are great at identifying rules from examples. '\n",
    "    'You will receive examples from the user where input is paired with True if it follows the rule and False otherwise. '\n",
    "    'Think step by step about what the rule is. '\n",
    "    'Finally summarize the thinking by outputting \"Rule:\" followed by the rule you identified.')\n",
    "    human_template_rule = '{examples}'\n",
    "    chat_prompt_rule = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template_rule),\n",
    "        (\"human\", human_template_rule),\n",
    "    ])\n",
    "\n",
    "    chain_rule = chat_prompt_rule | ChatOpenAI(model=model, temperature=0) | LabelOutputParser()\n",
    "\n",
    "    task_examples = [example for example in examples if example[\"task\"] == task]\n",
    "    context = create_context(task_examples)\n",
    "    response = chain_rule.invoke({\"examples\": context})\n",
    "\n",
    "    model_path = f'./data/articulation/{model}'\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    with open(f'{model_path}/{task}.txt', 'w') as f:\n",
    "        f.write(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = { \n",
    "    'gpt-3.5-turbo-1106': {},\n",
    "    'gpt-4-1106-preview': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task_accuracy(task: str, model = 'gpt-3.5-turbo-1106', share_in_context=0.6):\n",
    "    examples = load_examples()\n",
    "    accuracy = get_accuracy_for_task(task, examples, share_in_context=share_in_context)\n",
    "    print(f'Accuracy for {task}: {accuracy}')\n",
    "    accuracies[model][task] = accuracy\n",
    "    provide_reasoning(task, examples=examples, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about_animals',\n",
       " 'about_cat',\n",
       " 'contains_sun',\n",
       " 'ends_with_period',\n",
       " 'lowercase',\n",
       " 'number_start',\n",
       " 'word_length',\n",
       " 'word_length_extreme'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = set([d['task'] for d in load_examples()])\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo-1106': {'about_animals': 0.6875,\n",
       "  'contains_sun': 0.65625,\n",
       "  'number_start': 0.78125,\n",
       "  'word_length': 0.84375,\n",
       "  'word_length_extreme': 1.0,\n",
       "  'about_cat': 0.78125,\n",
       "  'lowercase': 0.53125,\n",
       "  'ends_with_period': 0.53125,\n",
       "  'about_food': 0.71875,\n",
       "  'question': 0.28125},\n",
       " 'gpt-4-1106-preview': {}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/accuracies.json', 'w') as f:\n",
    "    json.dump(accuracies, f)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'Why do we dream?' Label: True\n",
      "Input: 'Can fish breathe underwater?' Label: True\n",
      "Input: 'Is there life on other planets?' Label: True\n",
      "Input: 'Where is the nearest grocery store?' Label: True\n",
      "Input: 'How often should I water plants?' Label: True\n",
      "Input: 'What is your favorite color?' Label: True\n",
      "Input: 'What are black holes?' Label: True\n",
      "Input: 'Is Mars inhabited?' Label: True\n",
      "Input: 'What is the capital of France?' Label: True\n",
      "Input: 'Where did I leave my keys?' Label: True\n",
      "Input: 'Are all stars the same size?' Label: True\n",
      "Input: 'Who won the game last night?' Label: True\n",
      "Input: 'Deserts have very little rainfall.' Label: False\n",
      "Input: 'Are dinosaurs extinct?' Label: True\n",
      "Input: 'Can you help me with this?' Label: True\n",
      "Input: 'Can money buy happiness?' Label: True\n",
      "Input: 'Can computers think like humans?' Label: True\n",
      "Input: 'Trees grow leaves in the spring.' Label: False\n",
      "Input: 'Can plants grow without sunlight?' Label: True\n",
      "Input: 'Is global warming real?' Label: True\n",
      "Input: 'Birds migrate in search of warmer climates.' Label: False\n",
      "Input: 'How do airplanes fly?' Label: True\n",
      "Input: 'Why do we age?' Label: True\n",
      "Input: 'What is the speed of light?' Label: True\n",
      "Input: 'Why is the ocean salty?' Label: True\n",
      "Input: 'What time does the sun set?' Label: True\n",
      "Input: 'Flowers bloom in a variety of colors.' Label: False\n",
      "Input: 'Oceans cover most of the earth's surface.' Label: False\n",
      "Input: 'Is it raining outside?' Label: True\n",
      "Input: 'Do you speak any other languages?' Label: True\n",
      "Input: 'Are cats nocturnal animals?' Label: True\n",
      "Input: 'Mountains are often covered in snow.' Label: False\n",
      "Input: 'Why do leaves change color?' Label: True\n",
      "Input: 'Do plants need soil?' Label: True\n",
      "Input: 'Music is a form of art.' Label: False\n",
      "Input: 'Can dogs see in color?' Label: True\n",
      "Input: 'How do we measure time?' Label: True\n",
      "Input: 'What causes rainbows?' Label: True\n",
      "Input: 'Are we there yet?' Label: True\n",
      "Input: 'What is photosynthesis?' Label: True\n",
      "Input: 'Why is the sky blue?' Label: True\n",
      "Input: 'How does a plane fly?' Label: True\n",
      "Input: 'Is it safe to travel alone?' Label: True\n",
      "Input: 'How do you bake a cake?' Label: True\n",
      "Input: 'What causes thunder?' Label: True\n",
      "Input: 'What time is dinner?' Label: True\n",
      "Input: 'Do you like coffee?' Label: True\n",
      "Input: 'The sky appears blue during the day.' Label: False\n",
      "{'task': 'question', 'input': 'The moon orbits around the Earth.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Rain provides water for plants.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Butterflies have a life cycle including metamorphosis.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Cakes are popular for celebrations.', 'label': 'False'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=10.0).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=10.0).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=10.0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Cars are a common mode of transportation.', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Snow is common in cold climates.', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Computers have become essential in modern life.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'The internet connects people globally.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Books can be found in a library.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'A year has four seasons.', 'label': 'False'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=10.0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'The sun is a star in the solar system.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'The heart pumps blood throughout the body.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Leaves often change color in autumn.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Fish live in water.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Light travels faster than sound.', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Volcanoes can erupt and spew lava.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Art can be expressed in many forms.', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Polar bears live in cold climates.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Tea is a popular beverage worldwide.', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Ancient pyramids can be found in Egypt.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Bicycles are an eco-friendly mode of transport.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'The human brain is capable of complex thought.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Languages vary widely around the world.', 'label': 'False'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=10.0).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': 'Bees are essential for pollination.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'The Great Wall of China is centuries old.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Mathematics is a universal language.', 'label': 'False'}\n",
      "true_label: False llm_label: False\n",
      "{'task': 'question', 'input': \"Seasons are caused by the Earth's tilt.\", 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': \"The ocean's tides are influenced by the moon.\", 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Wind turbines generate renewable energy.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'Gravity is the force that attracts objects to each other.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'The human body has 206 bones.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "{'task': 'question', 'input': 'The Amazon is the largest rainforest on Earth.', 'label': 'False'}\n",
      "true_label: False llm_label: True\n",
      "Accuracy for question: 0.28125\n"
     ]
    }
   ],
   "source": [
    "evaluate_task_accuracy('question')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
